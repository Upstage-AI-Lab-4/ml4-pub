{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.init\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch  # pytorch 모델을 mlflow로 저장하기 위함\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(2024)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(2024)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = nn.Sequential(\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=1 - self.keep_prob)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(625, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(-1, 4 * 4 * 128)\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def load_model(model_path='saved_model.pth'):\n",
    "    model = CNNModel().to(device)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Model file not found. Training a new model...\")\n",
    "        train_and_evaluate_model()\n",
    "    # FutureWarning 해결을 위해 weights_only=True 설정\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict(model, input_data_list):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for input_data in input_data_list:\n",
    "            input_tensor = torch.from_numpy(input_data).float().to(device)\n",
    "            input_tensor = input_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "            outputs = model(input_tensor)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.append(predicted.item())\n",
    "    return predictions\n",
    "\n",
    "def train_and_evaluate_model():\n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "    # torch 버전이슈로 autolog 불가 \n",
    "    # mlflow.pytorch.autolog()\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 2\n",
    "    batch_size = 100\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: 1 - x),  # 이미지 반전\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # MNIST 데이터셋 로드\n",
    "    full_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # 데이터셋 분할 (80% 학습, 20% 검증)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = CNNModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    # MLflow experiment 시작\n",
    "    # ml_exp = mlflow.set_experiment(experiment_name='mnist')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param('learning_rate', learning_rate)\n",
    "        mlflow.log_param('epochs', training_epochs)\n",
    "        mlflow.log_param('batch_size', batch_size)\n",
    "\n",
    "        for epoch in range(training_epochs):\n",
    "            model.train()\n",
    "            avg_cost = 0\n",
    "\n",
    "            for X, Y in train_loader:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                hypothesis = model(X)\n",
    "                cost = criterion(hypothesis, Y)\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                avg_cost += cost / len(train_loader)\n",
    "\n",
    "            print(f'[Epoch: {epoch + 1:>4}] cost = {avg_cost:.9f}')\n",
    "            mlflow.log_metric(f'epoch_cost', avg_cost.item(), step=epoch + 1)\n",
    "\n",
    "            # 검증 단계\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "            print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            mlflow.log_metric(f'val_accuracy', val_accuracy, step=epoch + 1)\n",
    "\n",
    "            # 가장 좋은 모델 저장\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), 'saved_model.pth')\n",
    "                print(f'Best model saved with Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # MLflow에 모델 저장\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate_model()\n",
    "\n",
    "    # 테스트 데이터로 모델 평가\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: 1 - x),  # 이미지 반전\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "    model = load_model('saved_model.pth')\n",
    "    test_accuracy = evaluate_model(model, test_loader)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow 모델 로드 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mlf_model_name = \"cnn\"\n",
    "mlf_model_version = \"1\"\n",
    "model_uri = f\"models:/{mlf_model_name}/{mlf_model_version}\"\n",
    "\n",
    "loaded_model = mlflow.pytorch.load_model(model_uri)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: 1 - x),  # 이미지 반전\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# mlflow 모델 테스트\n",
    "test_accuracy = evaluate_model(loaded_model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
